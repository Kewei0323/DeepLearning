{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "\n",
    "# Configure the TF backend session\n",
    "tf_config = tf.ConfigProto(\n",
    "    gpu_options=tf.GPUOptions(allow_growth=False))\n",
    "K.set_session(tf.Session(config=tf_config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-06-08 17:54:33--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 202.38.64.9\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|202.38.64.9|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87910968 (84M) [application/x-hdf]\n",
      "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
      "\n",
      "/tmp/inception_v3_w 100%[===================>]  83.84M  28.6KB/s    in 21m 45s \n",
      "\n",
      "2018-06-08 18:16:20 (65.8 KB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "pre_trained_model = InceptionV3(\n",
    "    input_shape=(150, 150, 3), include_top=False, weights=None)\n",
    "pre_trained_model.load_weights(local_weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape: (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape:', last_layer.output_shape)\n",
    "last_output = last_layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)\n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Configure and compile the model\n",
    "model = Model(pre_trained_model.input, x)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=RMSprop(lr=0.0001),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp')\n",
    "zip_ref.close()\n",
    "\n",
    "# Define our example directories and files\n",
    "base_dir = '/tmp/cats_and_dogs_filtered'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "\n",
    "# Directory with our training cat pictures\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "\n",
    "# Directory with our training dog pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "# Directory with our validation cat pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "\n",
    "# Directory with our validation dog pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "\n",
    "train_cat_fnames = os.listdir(train_cats_dir)\n",
    "train_dog_fnames = os.listdir(train_dogs_dir)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir, # This is the source directory for training images\n",
    "        target_size=(150, 150),  # All images will be resized to 150x150\n",
    "        batch_size=20,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      " - 242s - loss: 0.4975 - acc: 0.7650 - val_loss: 0.1894 - val_acc: 0.9260\n",
      "Epoch 2/2\n",
      " - 239s - loss: 0.3800 - acc: 0.8295 - val_loss: 0.3262 - val_acc: 0.8820\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=2,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unfreeze = False\n",
    "\n",
    "# Unfreeze all models after \"mixed6\"\n",
    "for layer in pre_trained_model.layers:\n",
    "  if unfreeze:\n",
    "    layer.trainable = True\n",
    "  if layer.name == 'mixed6':\n",
    "    unfreeze = True\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# As an optimizer, here we will use SGD \n",
    "# with a very low learning rate (0.00001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(lr=0.00001, momentum=0.9),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 233s - loss: 0.3530 - acc: 0.8410 - val_loss: 0.2574 - val_acc: 0.9030\n",
      "Epoch 2/50\n",
      " - 215s - loss: 0.2946 - acc: 0.8645 - val_loss: 0.2360 - val_acc: 0.9010\n",
      "Epoch 3/50\n",
      " - 216s - loss: 0.2966 - acc: 0.8725 - val_loss: 0.2319 - val_acc: 0.9070\n",
      "Epoch 4/50\n",
      " - 216s - loss: 0.2954 - acc: 0.8620 - val_loss: 0.2259 - val_acc: 0.9090\n",
      "Epoch 5/50\n",
      " - 216s - loss: 0.3058 - acc: 0.8690 - val_loss: 0.2258 - val_acc: 0.9090\n",
      "Epoch 6/50\n",
      " - 214s - loss: 0.3089 - acc: 0.8660 - val_loss: 0.2261 - val_acc: 0.9080\n",
      "Epoch 7/50\n",
      " - 214s - loss: 0.2820 - acc: 0.8835 - val_loss: 0.2240 - val_acc: 0.9100\n",
      "Epoch 8/50\n",
      " - 214s - loss: 0.3072 - acc: 0.8635 - val_loss: 0.2242 - val_acc: 0.9090\n",
      "Epoch 9/50\n",
      " - 214s - loss: 0.2830 - acc: 0.8790 - val_loss: 0.2235 - val_acc: 0.9100\n",
      "Epoch 10/50\n",
      " - 214s - loss: 0.2888 - acc: 0.8725 - val_loss: 0.2225 - val_acc: 0.9090\n",
      "Epoch 11/50\n",
      " - 214s - loss: 0.2887 - acc: 0.8765 - val_loss: 0.2227 - val_acc: 0.9090\n",
      "Epoch 12/50\n",
      " - 214s - loss: 0.2764 - acc: 0.8770 - val_loss: 0.2229 - val_acc: 0.9090\n",
      "Epoch 13/50\n",
      " - 214s - loss: 0.2948 - acc: 0.8695 - val_loss: 0.2230 - val_acc: 0.9070\n",
      "Epoch 14/50\n",
      " - 214s - loss: 0.2993 - acc: 0.8665 - val_loss: 0.2228 - val_acc: 0.9090\n",
      "Epoch 15/50\n",
      " - 214s - loss: 0.2748 - acc: 0.8815 - val_loss: 0.2206 - val_acc: 0.9090\n",
      "Epoch 16/50\n",
      " - 214s - loss: 0.2819 - acc: 0.8780 - val_loss: 0.2187 - val_acc: 0.9080\n",
      "Epoch 17/50\n",
      " - 214s - loss: 0.3012 - acc: 0.8690 - val_loss: 0.2197 - val_acc: 0.9080\n",
      "Epoch 18/50\n",
      " - 214s - loss: 0.2912 - acc: 0.8705 - val_loss: 0.2198 - val_acc: 0.9070\n",
      "Epoch 19/50\n",
      " - 214s - loss: 0.3059 - acc: 0.8720 - val_loss: 0.2199 - val_acc: 0.9090\n",
      "Epoch 20/50\n",
      " - 214s - loss: 0.3079 - acc: 0.8600 - val_loss: 0.2212 - val_acc: 0.9080\n",
      "Epoch 21/50\n",
      " - 214s - loss: 0.2840 - acc: 0.8745 - val_loss: 0.2200 - val_acc: 0.9090\n",
      "Epoch 22/50\n",
      " - 214s - loss: 0.2935 - acc: 0.8745 - val_loss: 0.2188 - val_acc: 0.9080\n",
      "Epoch 23/50\n",
      " - 214s - loss: 0.2839 - acc: 0.8725 - val_loss: 0.2195 - val_acc: 0.9090\n",
      "Epoch 24/50\n",
      " - 228s - loss: 0.2751 - acc: 0.8740 - val_loss: 0.2174 - val_acc: 0.9110\n",
      "Epoch 25/50\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=50,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50,\n",
    "      verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  plot the training and validation loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Retrieve a list of accuracy results on training and test data\n",
    "# sets for each training epoch\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "# Retrieve a list of list results on training and test data\n",
    "# sets for each training epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Get number of epochs\n",
    "epochs = range(len(acc))\n",
    "\n",
    "# Plot training and validation accuracy per epoch\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.title('Training and validation accuracy')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "# Plot training and validation loss per epoch\n",
    "plt.plot(epochs, loss)\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.title('Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, signal\n",
    "os.kill(os.getpid(), signal.SIGKILL)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
